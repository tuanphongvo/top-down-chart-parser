{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install graphviz"
      ],
      "metadata": {
        "id": "zvlW3EXlS2QL"
      },
      "id": "zvlW3EXlS2QL",
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import graphviz\n",
        "from collections import defaultdict\n",
        "from IPython.display import Image, display"
      ],
      "metadata": {
        "id": "MzZ2cd7reoHr"
      },
      "id": "MzZ2cd7reoHr",
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === NGỮ PHÁP TIẾNG VIỆT MỞ RỘNG ===\n",
        "VN_GRAMMAR = {\n",
        "    \"S\": [[\"NP\", \"VP\"]],\n",
        "\n",
        "    # Noun phrases\n",
        "    \"NP\": [[\"Pro\"], [\"N\"], [\"Det\", \"N\"], [\"N\", \"N\"], [\"NP\", \"PP\"]], # Added NP PP rule\n",
        "\n",
        "    # Verb phrases\n",
        "    \"VP\": [[\"V\"], [\"V\", \"NP\"], [\"V\", \"Adj\"], [\"V\", \"PP\"], [\"Adv\", \"V\"], [\"V\", \"V\"], [\"V\", \"Adv\"]], # Added V Adv rule\n",
        "\n",
        "    # Prepositional phrases\n",
        "    \"PP\": [[\"P\", \"NP\"]],\n",
        "\n",
        "    # Pronouns\n",
        "    \"Pro\": [[\"tôi\"], [\"em\"], [\"anh\"], [\"chị\"], [\"bạn\"], [\"bố\"], [\"mẹ\"], [\"bé\"], [\"con\"]], # Removed Ông, Bà as they might be part of \"Ông bà\"\n",
        "\n",
        "    # Nouns\n",
        "    \"N\": [\n",
        "        [\"cơm\"], [\"bài\"], [\"chợ\"], [\"sách\"], [\"hà nội\"], [\"cà phê\"], [\"phim\"],\n",
        "        [\"mèo\"], [\"chó\"], [\"cờ\"], [\"tranh\"], [\"búp bê\"], [\"nước\"], [\"báo\"], [\"mì\"],\n",
        "        [\"xe\"], [\"bánh\"], [\"nhạc\"], [\"thư\"], [\"cây\"], [\"đồ\"], [\"tivi\"], [\"truyện\"],\n",
        "        [\"sữa\"], [\"toán\"], [\"tiếng anh\"], [\"đồng hồ\"], [\"ảnh\"], [\"phòng\"], [\"hoa\"],\n",
        "        [\"đàn\"], [\"bộ\"], [\"chén\"], [\"trưa\"], [\"dạo\"], [\"điện\"], [\"ăn\"], [\"học\"], [\"làm\"],\n",
        "        [\"việc\"], [\"ông bà\"], [\"bà\"], [\"tôi\"], [\"sinh\"], [\"tố\"], [\"bánh mì\"], [\"sinh tố\"],\n",
        "        [\"cá koi\"], [\"học sinh\"],[\"sinh học\"],[\"anh ấy\"]\n",
        "    ],\n",
        "\n",
        "    # Determiners\n",
        "    \"Det\": [[\"con\"], [\"ông\"]],\n",
        "\n",
        "    # Verbs\n",
        "    \"V\": [\n",
        "        [\"ăn\"], [\"học\"], [\"đi\"], [\"đọc\"], [\"nấu\"], [\"yêu\"], [\"thích\"], [\"xem\"],\n",
        "        [\"ngủ\"], [\"sủa\"], [\"chơi\"], [\"uống\"], [\"chạy\"], [\"sửa\"], [\"làm\"], [\"nghe\"],\n",
        "        [\"mua\"], [\"viết\"], [\"tưới\"], [\"giặt\"], [\"ngồi\"], [\"gọi\"], [\"chờ\"], [\"rửa\"],\n",
        "        [\"dọn\"], [\"chụp\"], [\"thăm\"], [\"lái\"], [\"làm việc\"], [\"hát\"], [\"vẽ\"],\n",
        "        [\"chăm\"], [\"dạo\"]\n",
        "    ],\n",
        "\n",
        "    # Adjectives – Tính từ\n",
        "    \"Adj\": [\n",
        "        [\"nhanh\"],       # He runs fast → Anh ấy chạy nhanh (dùng như trạng từ, nhưng trong tiếng Việt hay dùng tính từ cho cả hai)\n",
        "        [\"cao\"],\n",
        "        [\"thấp\"],\n",
        "        [\"đẹp\"],\n",
        "        [\"xinh\"],\n",
        "        [\"giỏi\"],\n",
        "        [\"trẻ\"],\n",
        "        [\"mới\"],\n",
        "        [\"nóng\"],\n",
        "        [\"vui\"]\n",
        "    ],\n",
        "\n",
        "    \"Adv\": [\n",
        "        [\"rất\"],\n",
        "        [\"hơi\"],\n",
        "        [\"thường\"],\n",
        "        [\"luôn\"],\n",
        "        [\"cẩn thận\"],\n",
        "        [\"vội\"],\n",
        "        [\"chậm\"],\n",
        "        [\"đột ngột\"],\n",
        "        [\"từ tốn\"]\n",
        "    ],\n",
        "\n",
        "    # Prepositions\n",
        "    \"P\": [\n",
        "        [\"ở\"], [\"trong\"], [\"trên\"], [\"dưới\"], [\"với\"],\n",
        "        [\"bằng\"], [\"về\"], [\"từ\"], [\"đến\"], [\"qua\"]\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "id": "BvXfq0wQv55l"
      },
      "id": "BvXfq0wQv55l",
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === NODE CLASS FOR PARSE TREE ===\n",
        "class ParseNode:\n",
        "    def __init__(self, symbol, children=None, word=None):\n",
        "        self.symbol = symbol\n",
        "        self.children = children if children is not None else []\n",
        "        self.word = word  # For terminal nodes, store the actual word(s)\n",
        "\n",
        "    def __repr__(self):\n",
        "        if self.word:\n",
        "            return f\"{self.symbol}('{self.word}')\"\n",
        "        return f\"{self.symbol}({len(self.children)} children)\"\n",
        "\n",
        "# === STATE CLASS ===\n",
        "class State:\n",
        "    def __init__(self, lhs, rhs, dot, start, end, backpointers=None, node=None):\n",
        "        self.lhs = lhs\n",
        "        self.rhs = rhs\n",
        "        self.dot = dot\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "        self.backpointers = backpointers if backpointers else []  # Store (state, completed_state) pairs\n",
        "        self.node = node  # ParseNode associated with this state\n",
        "\n",
        "    def next_symbol(self):\n",
        "        return self.rhs[self.dot] if self.dot < len(self.rhs) else None\n",
        "\n",
        "    def is_complete(self):\n",
        "        return self.dot >= len(self.rhs)\n",
        "\n",
        "    def advance(self):\n",
        "        return State(self.lhs, self.rhs, self.dot + 1, self.start, self.end, self.backpointers)\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return (self.lhs, self.rhs, self.dot, self.start, self.end) == \\\n",
        "               (other.lhs, other.rhs, other.dot, other.start, other.end)\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash((self.lhs, tuple(self.rhs), self.dot, self.start, self.end))\n",
        "\n",
        "    def __repr__(self):\n",
        "        before_dot = ' '.join(self.rhs[:self.dot])\n",
        "        after_dot = ' '.join(self.rhs[self.dot:])\n",
        "        return f\"[{self.start}:{self.end}] {self.lhs} → {before_dot} • {after_dot}\"\n",
        "\n",
        "# === MODIFIED PARSER ===\n",
        "def parse_vietnamese(sentence, grammar=VN_GRAMMAR):\n",
        "    words = sentence.lower().strip().split()\n",
        "\n",
        "    n = len(words)\n",
        "    chart = [set() for _ in range(n + 1)]\n",
        "    # Initialize with start symbol\n",
        "    for rhs in grammar[\"S\"]:\n",
        "        chart[0].add(State(\"S\", rhs, 0, 0, 0))\n",
        "\n",
        "    for i in range(n + 1):\n",
        "        added = True\n",
        "        while added:\n",
        "            added = False\n",
        "            states = list(chart[i])\n",
        "            for state in states:\n",
        "                next_sym = state.next_symbol()\n",
        "\n",
        "                if next_sym in grammar:\n",
        "                    for prod in grammar[next_sym]:\n",
        "                        new_state = State(next_sym, prod, 0, i, i)\n",
        "                        if new_state not in chart[i]:\n",
        "                            chart[i].add(new_state)\n",
        "                            added = True\n",
        "\n",
        "                elif next_sym is not None and next_sym not in grammar:\n",
        "                    terminal_words = next_sym.split()\n",
        "                    terminal_len = len(terminal_words)\n",
        "                    if i + terminal_len <= n and words[i:i + terminal_len] == terminal_words:\n",
        "                        # Create a ParseNode for the terminal\n",
        "                        terminal_text = ' '.join(words[i:i + terminal_len])\n",
        "                        node = ParseNode(next_sym, word=terminal_text)\n",
        "                        new_state = State(state.lhs, state.rhs, state.dot + 1, state.start, i + terminal_len, state.backpointers, node)\n",
        "                        if new_state not in chart[i + terminal_len]:\n",
        "                            chart[i + terminal_len].add(new_state)\n",
        "                            added = True\n",
        "\n",
        "                elif state.is_complete():\n",
        "                    for st in chart[state.start]:\n",
        "                        if st.next_symbol() == state.lhs:\n",
        "                            # Create a ParseNode for the completed rule\n",
        "                            children = []\n",
        "                            backpointers = st.backpointers + [(st, state)]\n",
        "                            for _, completed_state in backpointers:\n",
        "                                if completed_state.node:\n",
        "                                    children.append(completed_state.node)\n",
        "                            node = ParseNode(st.lhs, children=children)\n",
        "                            new_state = State(st.lhs, st.rhs, st.dot + 1, st.start, i, backpointers, node)\n",
        "                            if new_state not in chart[i]:\n",
        "                                chart[i].add(new_state)\n",
        "                                added = True\n",
        "\n",
        "    # Check for success and collect parse trees\n",
        "    success = False\n",
        "    parse_trees = []\n",
        "    for state in chart[n]:\n",
        "        if state.lhs == \"S\" and state.start == 0 and state.end == n and state.is_complete():\n",
        "            success = True\n",
        "            if state.node:\n",
        "                parse_trees.append(state.node)\n",
        "            break\n",
        "\n",
        "    return success, chart, parse_trees\n",
        "# === 50 CÂU TIẾNG VIỆT ===\n",
        "sentences = [\n",
        "    \"Tôi ăn cơm\", \"Em học bài\", \"Chị đi chợ\", \"Bố đọc sách\", \"Mẹ nấu ăn\", \"Tôi yêu Hà Nội\", \"Anh thích cà phê\", \"Bạn xem phim\",\n",
        "    \"Con mèo ngủ\", \"Con chó sủa\", \"Ông bà chơi cờ\", \"Tôi hát\", \"Em vẽ tranh\", \"Bé chơi búp bê\", \"Tôi uống nước\", \"Anh đọc báo\",\n",
        "    \"Em chạy nhanh\", \"Chị nấu mì\", \"Bố sửa xe\", \"Mẹ làm bánh\", \"Tôi nghe nhạc\", \"Bạn làm bài\", \"Anh đi học\", \"Em mua sách\", \"Chị chơi đàn\",\n",
        "    \"Tôi đi bộ\", \"Anh rửa chén\", \"Em viết thư\", \"Bố tưới cây\", \"Mẹ giặt đồ\", \"Tôi ngủ trưa\", \"Em xem tivi\", \"Chị đi xe\", \"Anh học Toán\",\n",
        "    \"Tôi đi làm\", \"Bạn học tiếng Anh\", \"Em đọc truyện\", \"Anh uống sữa\", \"Chị thăm bà\", \"Tôi đi dạo\", \"Bạn ngồi học\", \"Mẹ gọi tôi\", \"Em xem đồng hồ\",\n",
        "    \"Tôi chờ xe\", \"Anh lái xe\", \"Chị làm việc\", \"Bạn gọi điện\", \"Tôi chụp ảnh\", \"Em dọn phòng\", \"Chị chăm hoa\"\n",
        "]\n",
        "\n",
        "# === CHẠY PARSER CHO 50 CÂU ===\n",
        "print(\"=== KIỂM TRA 50 CÂU TIẾNG VIỆT ===\\n\")\n",
        "passed = 0\n",
        "failed_sentences = []\n",
        "\n",
        "for s in sentences:\n",
        "    success, _, parse_trees = parse_vietnamese(s)\n",
        "    if success:\n",
        "        print(f\"THÀNH CÔNG: \\\"{s}\\\"\")\n",
        "        passed += 1\n",
        "    else:\n",
        "        print(f\"THẤT BẠI: \\\"{s}\\\"\")\n",
        "        failed_sentences.append(s)\n",
        "\n",
        "print(f\"\\nĐã phân tích thành công: {passed}/{len(sentences)} câu\")\n",
        "\n",
        "if failed_sentences:\n",
        "    print(\"\\n=== CÁC CÂU CHƯA PHÂN TÍCH ĐƯỢC ===\")\n",
        "    for s in failed_sentences:\n",
        "        print(f\"- \\\"{s}\\\"\")\n",
        "\n",
        "# === PHÂN TÍCH CÂU KHÓ ===\n",
        "def analyze_sentence(sentence):\n",
        "    \"\"\"Phân tích chi tiết câu và hiển thị trạng thái phân tích\"\"\"\n",
        "    print(f\"\\n=== PHÂN TÍCH CHI TIẾT: \\\"{sentence}\\\" ===\")\n",
        "    #words = sentence.strip().split()\n",
        "    success, chart, parse_trees = parse_vietnamese(sentence)\n",
        "\n",
        "    for i, states in enumerate(chart):\n",
        "        print(f\"\\nCHART[{i}]:\")\n",
        "        for state in sorted(states, key=lambda s: (s.start, s.lhs)):\n",
        "            print(f\"  {state}\")\n",
        "\n",
        "    if success:\n",
        "        print(f\"\\nTHÀNH CÔNG: Câu \\\"{sentence}\\\" được phân tích thành công\")\n",
        "    else:\n",
        "        print(f\"\\nTHẤT BẠI: Câu \\\"{sentence}\\\" không thể phân tích\")\n",
        "\n",
        "# Phân tích một số câu khó\n",
        "#problem_sentences = [\"Ông bà chơi cờ\", \"Mẹ nấu ăn\", \"Tôi đi bộ\", \"Tôi đi làm\"]\n",
        "#for sentence in problem_sentences:\n",
        "#    analyze_sentence(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkRpLzx9xYUY",
        "outputId": "5266d4dc-d09c-460e-c212-bccfeffb7beb"
      },
      "id": "DkRpLzx9xYUY",
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== KIỂM TRA 50 CÂU TIẾNG VIỆT ===\n",
            "\n",
            "THÀNH CÔNG: \"Tôi ăn cơm\"\n",
            "THÀNH CÔNG: \"Em học bài\"\n",
            "THÀNH CÔNG: \"Chị đi chợ\"\n",
            "THÀNH CÔNG: \"Bố đọc sách\"\n",
            "THÀNH CÔNG: \"Mẹ nấu ăn\"\n",
            "THÀNH CÔNG: \"Tôi yêu Hà Nội\"\n",
            "THÀNH CÔNG: \"Anh thích cà phê\"\n",
            "THÀNH CÔNG: \"Bạn xem phim\"\n",
            "THÀNH CÔNG: \"Con mèo ngủ\"\n",
            "THÀNH CÔNG: \"Con chó sủa\"\n",
            "THÀNH CÔNG: \"Ông bà chơi cờ\"\n",
            "THÀNH CÔNG: \"Tôi hát\"\n",
            "THÀNH CÔNG: \"Em vẽ tranh\"\n",
            "THÀNH CÔNG: \"Bé chơi búp bê\"\n",
            "THÀNH CÔNG: \"Tôi uống nước\"\n",
            "THÀNH CÔNG: \"Anh đọc báo\"\n",
            "THÀNH CÔNG: \"Em chạy nhanh\"\n",
            "THÀNH CÔNG: \"Chị nấu mì\"\n",
            "THÀNH CÔNG: \"Bố sửa xe\"\n",
            "THÀNH CÔNG: \"Mẹ làm bánh\"\n",
            "THÀNH CÔNG: \"Tôi nghe nhạc\"\n",
            "THÀNH CÔNG: \"Bạn làm bài\"\n",
            "THÀNH CÔNG: \"Anh đi học\"\n",
            "THÀNH CÔNG: \"Em mua sách\"\n",
            "THÀNH CÔNG: \"Chị chơi đàn\"\n",
            "THÀNH CÔNG: \"Tôi đi bộ\"\n",
            "THÀNH CÔNG: \"Anh rửa chén\"\n",
            "THÀNH CÔNG: \"Em viết thư\"\n",
            "THÀNH CÔNG: \"Bố tưới cây\"\n",
            "THÀNH CÔNG: \"Mẹ giặt đồ\"\n",
            "THÀNH CÔNG: \"Tôi ngủ trưa\"\n",
            "THÀNH CÔNG: \"Em xem tivi\"\n",
            "THÀNH CÔNG: \"Chị đi xe\"\n",
            "THÀNH CÔNG: \"Anh học Toán\"\n",
            "THÀNH CÔNG: \"Tôi đi làm\"\n",
            "THÀNH CÔNG: \"Bạn học tiếng Anh\"\n",
            "THÀNH CÔNG: \"Em đọc truyện\"\n",
            "THÀNH CÔNG: \"Anh uống sữa\"\n",
            "THÀNH CÔNG: \"Chị thăm bà\"\n",
            "THÀNH CÔNG: \"Tôi đi dạo\"\n",
            "THÀNH CÔNG: \"Bạn ngồi học\"\n",
            "THÀNH CÔNG: \"Mẹ gọi tôi\"\n",
            "THÀNH CÔNG: \"Em xem đồng hồ\"\n",
            "THÀNH CÔNG: \"Tôi chờ xe\"\n",
            "THÀNH CÔNG: \"Anh lái xe\"\n",
            "THÀNH CÔNG: \"Chị làm việc\"\n",
            "THÀNH CÔNG: \"Bạn gọi điện\"\n",
            "THÀNH CÔNG: \"Tôi chụp ảnh\"\n",
            "THÀNH CÔNG: \"Em dọn phòng\"\n",
            "THÀNH CÔNG: \"Chị chăm hoa\"\n",
            "\n",
            "Đã phân tích thành công: 50/50 câu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Phân tích một số câu khó\n",
        "problem_sentences = [\"Ông bà chơi cờ\", \"Mẹ nấu ăn\", \"Tôi đi bộ\", \"Tôi đi làm\"]\n",
        "problem_sentences = [\"Tôi đi làm\"]\n",
        "#for sentence in problem_sentences:\n",
        "#    analyze_sentence(sentence)"
      ],
      "metadata": {
        "id": "3jWkfy0204ui"
      },
      "id": "3jWkfy0204ui",
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === VISUALIZE PARSE TREE FUNCTION ===\n",
        "def visualize_parse_tree(sentence, output_file=\"parse_tree\", format=\"png\"):\n",
        "    \"\"\"\n",
        "    Visualizes the parse tree for a given Vietnamese sentence.\n",
        "    Args:\n",
        "        sentence (str): The input sentence to parse and visualize.\n",
        "        output_file (str): Base name for the output file (without extension).\n",
        "        format (str): Output format (e.g., 'png', 'pdf').\n",
        "    Returns:\n",
        "        bool: True if visualization was successful, False otherwise.\n",
        "    \"\"\"\n",
        "    # Parse the sentence\n",
        "    success, _, parse_trees = parse_vietnamese(sentence)\n",
        "\n",
        "    if not success or not parse_trees:\n",
        "        print(f\"Failed to parse sentence: \\\"{sentence}\\\"\")\n",
        "        return False\n",
        "\n",
        "    # Use the first parse tree (if multiple exist)\n",
        "    parse_tree = parse_trees[0]\n",
        "\n",
        "    # Create a Graphviz Digraph\n",
        "    dot = graphviz.Digraph(comment=f\"Parse Tree for: {sentence}\", format=format)\n",
        "    dot.attr(rankdir=\"TB\")  # Top to Bottom\n",
        "\n",
        "    # Counter for unique node IDs\n",
        "    node_id = 0\n",
        "    node_map = {}  # Maps ParseNode objects to Graphviz node IDs\n",
        "\n",
        "    def add_node(node):\n",
        "        nonlocal node_id\n",
        "        # Create a unique ID for the node\n",
        "        current_id = f\"n{node_id}\"\n",
        "        node_id += 1\n",
        "        node_map[node] = current_id\n",
        "\n",
        "        # Label the node\n",
        "        if node.word:\n",
        "            label = f\"{node.symbol}\\n({node.word})\"\n",
        "        else:\n",
        "            label = node.symbol\n",
        "\n",
        "        # Add the node to the graph\n",
        "        dot.node(current_id, label)\n",
        "\n",
        "        # Recursively add children\n",
        "        for child in node.children:\n",
        "            child_id = add_node(child)\n",
        "            dot.edge(current_id, child_id)\n",
        "\n",
        "        return current_id\n",
        "\n",
        "    # Build the graph starting from the root\n",
        "    add_node(parse_tree)\n",
        "\n",
        "    # Render the graph\n",
        "    try:\n",
        "        dot.render(output_file, view=False, cleanup=False)\n",
        "        print(f\"Parse tree saved as {output_file}.{format}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error rendering parse tree: {e}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "oinyT4incjhq"
      },
      "id": "oinyT4incjhq",
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_grammar_tree_graphviz(grammar, show_terminals=False):\n",
        "    \"\"\"\n",
        "    Tạo biểu đồ cây cú pháp sử dụng Graphviz\n",
        "\n",
        "    Args:\n",
        "        grammar: Từ điển chứa các luật ngữ pháp\n",
        "        show_terminals: Có hiển thị các từ kết thúc (terminal words) hay không\n",
        "\n",
        "    Returns:\n",
        "        Đối tượng Graphviz Digraph\n",
        "    \"\"\"\n",
        "    # Tạo đối tượng Digraph\n",
        "    dot = graphviz.Digraph(comment='Grammar Tree')\n",
        "    dot.attr('node', shape='box', style='filled', fillcolor='#f9f9f9')\n",
        "\n",
        "    node_count = 0\n",
        "    node_map = {}  # Lưu ánh xạ giữa non-terminal và ID node\n",
        "\n",
        "    # Tạo những nút gốc cho các loại cấu trúc ngữ pháp\n",
        "    for symbol in grammar:\n",
        "        node_id = f\"{symbol}_{node_count}\"\n",
        "        node_map[symbol] = node_id\n",
        "        dot.node(node_id, symbol)\n",
        "        node_count += 1\n",
        "\n",
        "    # Xử lý các luật mở rộng cho mỗi ký hiệu phi kết thúc (non-terminal)\n",
        "    for symbol, expansions in grammar.items():\n",
        "        parent_node = node_map[symbol]  # Lấy nút gốc cho ký hiệu\n",
        "\n",
        "        # Xử lý mỗi luật mở rộng\n",
        "        for i, expansion in enumerate(expansions):\n",
        "            # Kiểm tra xem expansion có chứa terminal nodes không\n",
        "            contains_only_terminals = all(comp not in grammar for comp in expansion)\n",
        "\n",
        "            # Nếu chỉ chứa terminals và không hiển thị terminals, thì bỏ qua\n",
        "            if contains_only_terminals and not show_terminals:\n",
        "                continue\n",
        "\n",
        "            # Tạo một nút mở rộng cho mỗi luật - bỏ qua các terminal words nếu show_terminals=False\n",
        "            if show_terminals:\n",
        "                expansion_label = f\"{symbol}: {' '.join(expansion)}\"\n",
        "            else:\n",
        "                # Chỉ hiển thị các non-terminals trong expansion\n",
        "                non_terminal_parts = [comp for comp in expansion if comp in grammar]\n",
        "                if non_terminal_parts:  # Chỉ hiển thị nếu có non-terminals\n",
        "                    expansion_label = f\"{symbol}: {' '.join(non_terminal_parts)}\"\n",
        "                else:\n",
        "                    # Nếu expansion chỉ chứa terminals, hiển thị tên symbol để người dùng biết luật tồn tại\n",
        "                    expansion_label = f\"{symbol}: ...\"\n",
        "\n",
        "            expansion_id = f\"{symbol}_exp_{i}\"\n",
        "            dot.node(expansion_id, expansion_label, fillcolor='#e6f3ff')\n",
        "            dot.edge(parent_node, expansion_id)\n",
        "\n",
        "            # Xử lý từng thành phần trong luật mở rộng\n",
        "            for j, component in enumerate(expansion):\n",
        "                # Chỉ xử lý các non-terminals\n",
        "                if component in grammar:\n",
        "                    # Kết nối đến nút gốc của nó\n",
        "                    child_node = node_map[component]\n",
        "                    dot.edge(expansion_id, child_node)\n",
        "                elif show_terminals:  # Chỉ hiển thị terminals khi show_terminals=True\n",
        "                    terminal_id = f\"term_{node_count}\"\n",
        "                    dot.node(terminal_id, component, fillcolor='#f0e6ff')\n",
        "                    dot.edge(expansion_id, terminal_id)\n",
        "                    node_count += 1\n",
        "\n",
        "    return dot\n",
        "\n",
        "# Tạo biểu đồ cây cú pháp (không hiển thị các từ kết thúc)\n",
        "graph = visualize_grammar_tree_graphviz(VN_GRAMMAR, show_terminals=False)\n",
        "\n",
        "# Hiển thị biểu đồ\n",
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        },
        "id": "j09ZGRuwXlQa",
        "outputId": "4ed1fda2-d5d2-4028-bff4-177f192204c6"
      },
      "id": "j09ZGRuwXlQa",
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"834pt\" height=\"620pt\"\n viewBox=\"0.00 0.00 834.12 620.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 616)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-616 830.12,-616 830.12,4 -4,4\"/>\n<!-- S_0 -->\n<g id=\"node1\" class=\"node\">\n<title>S_0</title>\n<polygon fill=\"#f9f9f9\" stroke=\"black\" points=\"351.62,-612 297.62,-612 297.62,-576 351.62,-576 351.62,-612\"/>\n<text text-anchor=\"middle\" x=\"324.62\" y=\"-590.3\" font-family=\"Times,serif\" font-size=\"14.00\">S</text>\n</g>\n<!-- S_exp_0 -->\n<g id=\"node12\" class=\"node\">\n<title>S_exp_0</title>\n<polygon fill=\"#e6f3ff\" stroke=\"black\" points=\"359.12,-540 290.12,-540 290.12,-504 359.12,-504 359.12,-540\"/>\n<text text-anchor=\"middle\" x=\"324.62\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">S: NP VP</text>\n</g>\n<!-- S_0&#45;&gt;S_exp_0 -->\n<g id=\"edge1\" class=\"edge\">\n<title>S_0&#45;&gt;S_exp_0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M324.62,-575.7C324.62,-567.98 324.62,-558.71 324.62,-550.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"328.12,-550.1 324.62,-540.1 321.12,-550.1 328.12,-550.1\"/>\n</g>\n<!-- NP_1 -->\n<g id=\"node2\" class=\"node\">\n<title>NP_1</title>\n<polygon fill=\"#f9f9f9\" stroke=\"black\" points=\"239.62,-324 185.62,-324 185.62,-288 239.62,-288 239.62,-324\"/>\n<text text-anchor=\"middle\" x=\"212.62\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">NP</text>\n</g>\n<!-- NP_exp_0 -->\n<g id=\"node13\" class=\"node\">\n<title>NP_exp_0</title>\n<polygon fill=\"#e6f3ff\" stroke=\"black\" points=\"323.62,-252 263.62,-252 263.62,-216 323.62,-216 323.62,-252\"/>\n<text text-anchor=\"middle\" x=\"293.62\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">NP: Pro</text>\n</g>\n<!-- NP_1&#45;&gt;NP_exp_0 -->\n<g id=\"edge4\" class=\"edge\">\n<title>NP_1&#45;&gt;NP_exp_0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M232.64,-287.7C242.75,-278.97 255.16,-268.24 266.14,-258.75\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"268.55,-261.29 273.83,-252.1 263.97,-255.99 268.55,-261.29\"/>\n</g>\n<!-- NP_exp_1 -->\n<g id=\"node14\" class=\"node\">\n<title>NP_exp_1</title>\n<polygon fill=\"#e6f3ff\" stroke=\"black\" points=\"161.62,-252 107.62,-252 107.62,-216 161.62,-216 161.62,-252\"/>\n<text text-anchor=\"middle\" x=\"134.62\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">NP: N</text>\n</g>\n<!-- NP_1&#45;&gt;NP_exp_1 -->\n<g id=\"edge6\" class=\"edge\">\n<title>NP_1&#45;&gt;NP_exp_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M193.34,-287.7C183.7,-279.05 171.89,-268.45 161.39,-259.03\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"163.46,-256.18 153.68,-252.1 158.78,-261.39 163.46,-256.18\"/>\n</g>\n<!-- NP_exp_2 -->\n<g id=\"node15\" class=\"node\">\n<title>NP_exp_2</title>\n<polygon fill=\"#e6f3ff\" stroke=\"black\" points=\"89.62,-252 15.62,-252 15.62,-216 89.62,-216 89.62,-252\"/>\n<text text-anchor=\"middle\" x=\"52.62\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">NP: Det N</text>\n</g>\n<!-- NP_1&#45;&gt;NP_exp_2 -->\n<g id=\"edge8\" class=\"edge\">\n<title>NP_1&#45;&gt;NP_exp_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M185.48,-293.13C161.85,-282.79 127.08,-267.58 99.04,-255.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"100.38,-252.07 89.81,-251.27 97.57,-258.49 100.38,-252.07\"/>\n</g>\n<!-- NP_exp_3 -->\n<g id=\"node16\" class=\"node\">\n<title>NP_exp_3</title>\n<polygon fill=\"#e6f3ff\" stroke=\"black\" points=\"245.12,-252 180.12,-252 180.12,-216 245.12,-216 245.12,-252\"/>\n<text text-anchor=\"middle\" x=\"212.62\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">NP: N N</text>\n</g>\n<!-- NP_1&#45;&gt;NP_exp_3 -->\n<g id=\"edge11\" class=\"edge\">\n<title>NP_1&#45;&gt;NP_exp_3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M212.62,-287.7C212.62,-279.98 212.62,-270.71 212.62,-262.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"216.12,-262.1 212.62,-252.1 209.12,-262.1 216.12,-262.1\"/>\n</g>\n<!-- NP_exp_4 -->\n<g id=\"node17\" class=\"node\">\n<title>NP_exp_4</title>\n<polygon fill=\"#e6f3ff\" stroke=\"black\" points=\"419.12,-252 342.12,-252 342.12,-216 419.12,-216 419.12,-252\"/>\n<text text-anchor=\"middle\" x=\"380.62\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">NP: NP PP</text>\n</g>\n<!-- NP_1&#45;&gt;NP_exp_4 -->\n<g id=\"edge14\" class=\"edge\">\n<title>NP_1&#45;&gt;NP_exp_4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M239.93,-291.34C264.95,-280.28 302.36,-264.63 332.37,-252.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"333.83,-255.81 341.83,-248.87 331.24,-249.31 333.83,-255.81\"/>\n</g>\n<!-- VP_2 -->\n<g id=\"node3\" class=\"node\">\n<title>VP_2</title>\n<polygon fill=\"#f9f9f9\" stroke=\"black\" points=\"514.62,-468 460.62,-468 460.62,-432 514.62,-432 514.62,-468\"/>\n<text text-anchor=\"middle\" x=\"487.62\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">VP</text>\n</g>\n<!-- VP_exp_0 -->\n<g id=\"node18\" class=\"node\">\n<title>VP_exp_0</title>\n<polygon fill=\"#e6f3ff\" stroke=\"black\" points=\"554.62,-396 500.62,-396 500.62,-360 554.62,-360 554.62,-396\"/>\n<text text-anchor=\"middle\" x=\"527.62\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">VP: V</text>\n</g>\n<!-- VP_2&#45;&gt;VP_exp_0 -->\n<g id=\"edge17\" class=\"edge\">\n<title>VP_2&#45;&gt;VP_exp_0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M497.51,-431.7C502.11,-423.64 507.68,-413.89 512.77,-404.98\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"515.92,-406.52 517.85,-396.1 509.85,-403.05 515.92,-406.52\"/>\n</g>\n<!-- VP_exp_1 -->\n<g id=\"node19\" class=\"node\">\n<title>VP_exp_1</title>\n<polygon fill=\"#e6f3ff\" stroke=\"black\" points=\"302.12,-396 231.12,-396 231.12,-360 302.12,-360 302.12,-396\"/>\n<text text-anchor=\"middle\" x=\"266.62\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">VP: V NP</text>\n</g>\n<!-- VP_2&#45;&gt;VP_exp_1 -->\n<g id=\"edge19\" class=\"edge\">\n<title>VP_2&#45;&gt;VP_exp_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M460.6,-441.49C427.73,-432.21 370.37,-415.6 312.13,-396.06\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"313,-392.66 302.4,-392.77 310.75,-399.29 313,-392.66\"/>\n</g>\n<!-- VP_exp_2 -->\n<g id=\"node20\" class=\"node\">\n<title>VP_exp_2</title>\n<polygon fill=\"#e6f3ff\" stroke=\"black\" points=\"394.62,-396 320.62,-396 320.62,-360 394.62,-360 394.62,-396\"/>\n<text text-anchor=\"middle\" x=\"357.62\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">VP: V Adj</text>\n</g>\n<!-- VP_2&#45;&gt;VP_exp_2 -->\n<g id=\"edge22\" class=\"edge\">\n<title>VP_2&#45;&gt;VP_exp_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M460.37,-434.33C442.42,-424.66 418.59,-411.83 398.4,-400.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"399.88,-397.78 389.42,-396.12 396.56,-403.94 399.88,-397.78\"/>\n</g>\n<!-- VP_exp_3 -->\n<g id=\"node21\" class=\"node\">\n<title>VP_exp_3</title>\n<polygon fill=\"#e6f3ff\" stroke=\"black\" points=\"482.12,-396 413.12,-396 413.12,-360 482.12,-360 482.12,-396\"/>\n<text text-anchor=\"middle\" x=\"447.62\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">VP: V PP</text>\n</g>\n<!-- VP_2&#45;&gt;VP_exp_3 -->\n<g id=\"edge25\" class=\"edge\">\n<title>VP_2&#45;&gt;VP_exp_3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M477.73,-431.7C473.13,-423.64 467.56,-413.89 462.47,-404.98\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"465.39,-403.05 457.39,-396.1 459.32,-406.52 465.39,-403.05\"/>\n</g>\n<!-- VP_exp_4 -->\n<g id=\"node22\" class=\"node\">\n<title>VP_exp_4</title>\n<polygon fill=\"#e6f3ff\" stroke=\"black\" points=\"731.12,-396 654.12,-396 654.12,-360 731.12,-360 731.12,-396\"/>\n<text text-anchor=\"middle\" x=\"692.62\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">VP: Adv V</text>\n</g>\n<!-- VP_2&#45;&gt;VP_exp_4 -->\n<g id=\"edge28\" class=\"edge\">\n<title>VP_2&#45;&gt;VP_exp_4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M514.81,-440.1C544.49,-430.32 593.66,-414.01 644.42,-396.38\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"645.62,-399.67 653.92,-393.08 643.32,-393.06 645.62,-399.67\"/>\n</g>\n<!-- VP_exp_5 -->\n<g id=\"node23\" class=\"node\">\n<title>VP_exp_5</title>\n<polygon fill=\"#e6f3ff\" stroke=\"black\" points=\"636.12,-396 573.12,-396 573.12,-360 636.12,-360 636.12,-396\"/>\n<text text-anchor=\"middle\" x=\"604.62\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">VP: V V</text>\n</g>\n<!-- VP_2&#45;&gt;VP_exp_5 -->\n<g id=\"edge31\" class=\"edge\">\n<title>VP_2&#45;&gt;VP_exp_5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M514.76,-432.76C530.39,-423.41 550.27,-411.52 567.36,-401.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"569.21,-404.26 576,-396.12 565.62,-398.25 569.21,-404.26\"/>\n</g>\n<!-- VP_exp_6 -->\n<g id=\"node24\" class=\"node\">\n<title>VP_exp_6</title>\n<polygon fill=\"#e6f3ff\" stroke=\"black\" points=\"826.12,-396 749.12,-396 749.12,-360 826.12,-360 826.12,-396\"/>\n<text text-anchor=\"middle\" x=\"787.62\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">VP: V Adv</text>\n</g>\n<!-- VP_2&#45;&gt;VP_exp_6 -->\n<g id=\"edge34\" class=\"edge\">\n<title>VP_2&#45;&gt;VP_exp_6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M514.88,-444.59C559.9,-437.02 652.66,-420.26 739.32,-396.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"740.36,-399.53 749.03,-393.44 738.46,-392.79 740.36,-399.53\"/>\n</g>\n<!-- PP_3 -->\n<g id=\"node4\" class=\"node\">\n<title>PP_3</title>\n<polygon fill=\"#f9f9f9\" stroke=\"black\" points=\"407.62,-180 353.62,-180 353.62,-144 407.62,-144 407.62,-180\"/>\n<text text-anchor=\"middle\" x=\"380.62\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">PP</text>\n</g>\n<!-- PP_exp_0 -->\n<g id=\"node25\" class=\"node\">\n<title>PP_exp_0</title>\n<polygon fill=\"#e6f3ff\" stroke=\"black\" points=\"217.62,-108 149.62,-108 149.62,-72 217.62,-72 217.62,-108\"/>\n<text text-anchor=\"middle\" x=\"183.62\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">PP: P NP</text>\n</g>\n<!-- PP_3&#45;&gt;PP_exp_0 -->\n<g id=\"edge37\" class=\"edge\">\n<title>PP_3&#45;&gt;PP_exp_0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M353.23,-151.27C320.72,-139.71 266.07,-120.3 227.61,-106.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"228.31,-103.17 217.72,-103.12 225.97,-109.76 228.31,-103.17\"/>\n</g>\n<!-- Pro_4 -->\n<g id=\"node5\" class=\"node\">\n<title>Pro_4</title>\n<polygon fill=\"#f9f9f9\" stroke=\"black\" points=\"320.62,-180 266.62,-180 266.62,-144 320.62,-144 320.62,-180\"/>\n<text text-anchor=\"middle\" x=\"293.62\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Pro</text>\n</g>\n<!-- N_5 -->\n<g id=\"node6\" class=\"node\">\n<title>N_5</title>\n<polygon fill=\"#f9f9f9\" stroke=\"black\" points=\"200.62,-180 146.62,-180 146.62,-144 200.62,-144 200.62,-180\"/>\n<text text-anchor=\"middle\" x=\"173.62\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">N</text>\n</g>\n<!-- Det_6 -->\n<g id=\"node7\" class=\"node\">\n<title>Det_6</title>\n<polygon fill=\"#f9f9f9\" stroke=\"black\" points=\"79.62,-180 25.62,-180 25.62,-144 79.62,-144 79.62,-180\"/>\n<text text-anchor=\"middle\" x=\"52.62\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Det</text>\n</g>\n<!-- V_7 -->\n<g id=\"node8\" class=\"node\">\n<title>V_7</title>\n<polygon fill=\"#f9f9f9\" stroke=\"black\" points=\"592.62,-324 538.62,-324 538.62,-288 592.62,-288 592.62,-324\"/>\n<text text-anchor=\"middle\" x=\"565.62\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">V</text>\n</g>\n<!-- Adj_8 -->\n<g id=\"node9\" class=\"node\">\n<title>Adj_8</title>\n<polygon fill=\"#f9f9f9\" stroke=\"black\" points=\"384.62,-324 330.62,-324 330.62,-288 384.62,-288 384.62,-324\"/>\n<text text-anchor=\"middle\" x=\"357.62\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">Adj</text>\n</g>\n<!-- Adv_9 -->\n<g id=\"node10\" class=\"node\">\n<title>Adv_9</title>\n<polygon fill=\"#f9f9f9\" stroke=\"black\" points=\"766.62,-324 712.62,-324 712.62,-288 766.62,-288 766.62,-324\"/>\n<text text-anchor=\"middle\" x=\"739.62\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">Adv</text>\n</g>\n<!-- P_10 -->\n<g id=\"node11\" class=\"node\">\n<title>P_10</title>\n<polygon fill=\"#f9f9f9\" stroke=\"black\" points=\"210.62,-36 156.62,-36 156.62,0 210.62,0 210.62,-36\"/>\n<text text-anchor=\"middle\" x=\"183.62\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">P</text>\n</g>\n<!-- S_exp_0&#45;&gt;NP_1 -->\n<g id=\"edge2\" class=\"edge\">\n<title>S_exp_0&#45;&gt;NP_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M304.64,-503.88C280.33,-481.72 240.23,-440.64 221.62,-396 213.47,-376.44 211.45,-352.45 211.34,-334.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"214.84,-334.16 211.47,-324.11 207.84,-334.07 214.84,-334.16\"/>\n</g>\n<!-- S_exp_0&#45;&gt;VP_2 -->\n<g id=\"edge3\" class=\"edge\">\n<title>S_exp_0&#45;&gt;VP_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M359.19,-506.15C386.19,-494.56 423.62,-478.49 451.1,-466.68\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"452.57,-469.86 460.38,-462.7 449.81,-463.43 452.57,-469.86\"/>\n</g>\n<!-- NP_exp_0&#45;&gt;Pro_4 -->\n<g id=\"edge5\" class=\"edge\">\n<title>NP_exp_0&#45;&gt;Pro_4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M293.62,-215.7C293.62,-207.98 293.62,-198.71 293.62,-190.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"297.12,-190.1 293.62,-180.1 290.12,-190.1 297.12,-190.1\"/>\n</g>\n<!-- NP_exp_1&#45;&gt;N_5 -->\n<g id=\"edge7\" class=\"edge\">\n<title>NP_exp_1&#45;&gt;N_5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M144.26,-215.7C148.75,-207.64 154.18,-197.89 159.14,-188.98\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"162.28,-190.54 164.09,-180.1 156.17,-187.14 162.28,-190.54\"/>\n</g>\n<!-- NP_exp_2&#45;&gt;N_5 -->\n<g id=\"edge10\" class=\"edge\">\n<title>NP_exp_2&#45;&gt;N_5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M82.22,-215.88C98.9,-206.23 119.87,-194.1 137.51,-183.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"139.49,-186.79 146.39,-178.75 135.99,-180.73 139.49,-186.79\"/>\n</g>\n<!-- NP_exp_2&#45;&gt;Det_6 -->\n<g id=\"edge9\" class=\"edge\">\n<title>NP_exp_2&#45;&gt;Det_6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M52.62,-215.7C52.62,-207.98 52.62,-198.71 52.62,-190.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"56.12,-190.1 52.62,-180.1 49.12,-190.1 56.12,-190.1\"/>\n</g>\n<!-- NP_exp_3&#45;&gt;N_5 -->\n<g id=\"edge12\" class=\"edge\">\n<title>NP_exp_3&#45;&gt;N_5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M197.06,-215.7C191.8,-207.73 186.22,-198.1 181.69,-189.26\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"184.77,-187.58 177.25,-180.1 178.47,-190.63 184.77,-187.58\"/>\n</g>\n<!-- NP_exp_3&#45;&gt;N_5 -->\n<g id=\"edge13\" class=\"edge\">\n<title>NP_exp_3&#45;&gt;N_5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M208.9,-215.7C205.2,-207.56 199.91,-197.69 194.47,-188.7\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"197.34,-186.69 189.05,-180.1 191.42,-190.43 197.34,-186.69\"/>\n</g>\n<!-- NP_exp_4&#45;&gt;NP_1 -->\n<g id=\"edge15\" class=\"edge\">\n<title>NP_exp_4&#45;&gt;NP_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M345.7,-252C317.48,-264.3 278.04,-280.67 249.35,-291.94\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"247.74,-288.82 239.69,-295.7 250.28,-295.34 247.74,-288.82\"/>\n</g>\n<!-- NP_exp_4&#45;&gt;PP_3 -->\n<g id=\"edge16\" class=\"edge\">\n<title>NP_exp_4&#45;&gt;PP_3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M380.62,-215.7C380.62,-207.98 380.62,-198.71 380.62,-190.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"384.12,-190.1 380.62,-180.1 377.12,-190.1 384.12,-190.1\"/>\n</g>\n<!-- VP_exp_0&#45;&gt;V_7 -->\n<g id=\"edge18\" class=\"edge\">\n<title>VP_exp_0&#45;&gt;V_7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M537.01,-359.7C541.39,-351.64 546.68,-341.89 551.52,-332.98\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"554.64,-334.56 556.34,-324.1 548.49,-331.22 554.64,-334.56\"/>\n</g>\n<!-- VP_exp_1&#45;&gt;NP_1 -->\n<g id=\"edge21\" class=\"edge\">\n<title>VP_exp_1&#45;&gt;NP_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M253.27,-359.7C246.86,-351.39 239.06,-341.28 232.01,-332.14\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"234.69,-329.88 225.82,-324.1 229.15,-334.16 234.69,-329.88\"/>\n</g>\n<!-- VP_exp_1&#45;&gt;V_7 -->\n<g id=\"edge20\" class=\"edge\">\n<title>VP_exp_1&#45;&gt;V_7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M302.31,-362.94C305.44,-361.89 308.57,-360.89 311.62,-360 387.53,-337.89 478.75,-321.18 528.6,-312.87\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"529.29,-316.3 538.59,-311.22 528.15,-309.39 529.29,-316.3\"/>\n</g>\n<!-- VP_exp_2&#45;&gt;V_7 -->\n<g id=\"edge23\" class=\"edge\">\n<title>VP_exp_2&#45;&gt;V_7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M394.73,-363.15C397.74,-362.07 400.73,-361.01 403.62,-360 446.42,-345.1 495.99,-329.05 528.91,-318.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"530.1,-321.87 538.57,-315.5 527.98,-315.2 530.1,-321.87\"/>\n</g>\n<!-- VP_exp_2&#45;&gt;Adj_8 -->\n<g id=\"edge24\" class=\"edge\">\n<title>VP_exp_2&#45;&gt;Adj_8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M357.62,-359.7C357.62,-351.98 357.62,-342.71 357.62,-334.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"361.12,-334.1 357.62,-324.1 354.12,-334.1 361.12,-334.1\"/>\n</g>\n<!-- VP_exp_3&#45;&gt;PP_3 -->\n<g id=\"edge27\" class=\"edge\">\n<title>VP_exp_3&#45;&gt;PP_3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M448.73,-359.66C450,-329.15 449.55,-264.51 427.62,-216 422.89,-205.53 415.35,-195.65 407.69,-187.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"410.17,-184.85 400.69,-180.12 405.16,-189.73 410.17,-184.85\"/>\n</g>\n<!-- VP_exp_3&#45;&gt;V_7 -->\n<g id=\"edge26\" class=\"edge\">\n<title>VP_exp_3&#45;&gt;V_7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M476.49,-359.88C492.38,-350.45 512.25,-338.66 529.2,-328.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"531.45,-331.34 538.27,-323.23 527.88,-325.32 531.45,-331.34\"/>\n</g>\n<!-- VP_exp_4&#45;&gt;V_7 -->\n<g id=\"edge30\" class=\"edge\">\n<title>VP_exp_4&#45;&gt;V_7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M661.55,-359.88C643.5,-349.93 620.68,-337.35 601.82,-326.95\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"603.36,-323.81 592.92,-322.05 599.99,-329.94 603.36,-323.81\"/>\n</g>\n<!-- VP_exp_4&#45;&gt;Adv_9 -->\n<g id=\"edge29\" class=\"edge\">\n<title>VP_exp_4&#45;&gt;Adv_9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M704.24,-359.7C709.76,-351.47 716.47,-341.48 722.55,-332.42\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"725.47,-334.36 728.14,-324.1 719.66,-330.46 725.47,-334.36\"/>\n</g>\n<!-- VP_exp_5&#45;&gt;V_7 -->\n<g id=\"edge32\" class=\"edge\">\n<title>VP_exp_5&#45;&gt;V_7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M589.06,-359.7C583.8,-351.73 578.22,-342.1 573.69,-333.26\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"576.77,-331.58 569.25,-324.1 570.47,-334.63 576.77,-331.58\"/>\n</g>\n<!-- VP_exp_5&#45;&gt;V_7 -->\n<g id=\"edge33\" class=\"edge\">\n<title>VP_exp_5&#45;&gt;V_7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M600.9,-359.7C597.2,-351.56 591.91,-341.69 586.47,-332.7\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"589.34,-330.69 581.05,-324.1 583.42,-334.43 589.34,-330.69\"/>\n</g>\n<!-- VP_exp_6&#45;&gt;V_7 -->\n<g id=\"edge35\" class=\"edge\">\n<title>VP_exp_6&#45;&gt;V_7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M748.95,-362.83C746.14,-361.85 743.34,-360.9 740.62,-360 693.32,-344.3 638.22,-327.92 602.67,-317.6\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"603.32,-314.15 592.74,-314.73 601.38,-320.87 603.32,-314.15\"/>\n</g>\n<!-- VP_exp_6&#45;&gt;Adv_9 -->\n<g id=\"edge36\" class=\"edge\">\n<title>VP_exp_6&#45;&gt;Adv_9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M775.76,-359.7C770.12,-351.47 763.27,-341.48 757.05,-332.42\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"759.89,-330.37 751.35,-324.1 754.12,-334.33 759.89,-330.37\"/>\n</g>\n<!-- PP_exp_0&#45;&gt;NP_1 -->\n<g id=\"edge39\" class=\"edge\">\n<title>PP_exp_0&#45;&gt;NP_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M149.32,-91.66C110.83,-94.38 49.47,-105.06 16.62,-144 4.39,-158.5 -7.13,-234.26 6.62,-252 27.09,-278.4 121.53,-293.96 175.15,-300.81\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"174.95,-304.31 185.3,-302.07 175.81,-297.37 174.95,-304.31\"/>\n</g>\n<!-- PP_exp_0&#45;&gt;P_10 -->\n<g id=\"edge38\" class=\"edge\">\n<title>PP_exp_0&#45;&gt;P_10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M183.62,-71.7C183.62,-63.98 183.62,-54.71 183.62,-46.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"187.12,-46.1 183.62,-36.1 180.12,-46.1 187.12,-46.1\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x786c9499b290>"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === VISUALIZE PARSE TREE FUNCTION ===\n",
        "def visualize_parse_tree(sentence, output_file=\"parse_tree\", format=\"png\"):\n",
        "    \"\"\"\n",
        "    Visualizes the parse tree for a given Vietnamese sentence.\n",
        "    Args:\n",
        "        sentence (str): The input sentence to parse and visualize.\n",
        "        output_file (str): Base name for the output file (without extension).\n",
        "        format (str): Output format (e.g., 'png', 'svg').\n",
        "    Returns:\n",
        "        bool: True if visualization was successful, False otherwise.\n",
        "    \"\"\"\n",
        "    # Parse the sentence\n",
        "    success, _, parse_trees = parse_vietnamese(sentence)\n",
        "\n",
        "    if not success or not parse_trees:\n",
        "        print(f\"Failed to parse sentence: \\\"{sentence}\\\"\")\n",
        "        return False\n",
        "\n",
        "    # Use the first parse tree (if multiple exist)\n",
        "    parse_tree = parse_trees[0]\n",
        "\n",
        "    # Create a Graphviz Digraph\n",
        "    dot = graphviz.Digraph(comment=f\"Parse Tree for: {sentence}\", format=format)\n",
        "    dot.attr(rankdir=\"TB\")  # Top to Bottom\n",
        "\n",
        "    # Counter for unique node IDs\n",
        "    node_id = 0\n",
        "    node_map = {}  # Maps ParseNode objects to Graphviz node IDs\n",
        "\n",
        "    def add_node(node):\n",
        "        nonlocal node_id\n",
        "        # Create a unique ID for the node\n",
        "        current_id = f\"n{node_id}\"\n",
        "        node_id += 1\n",
        "        node_map[node] = current_id\n",
        "\n",
        "        # Label the node\n",
        "        if node.word:\n",
        "            label = f\"{node.symbol}\\n({node.word})\"\n",
        "        else:\n",
        "            label = node.symbol\n",
        "\n",
        "        # Add the node to the graph\n",
        "        dot.node(current_id, label)\n",
        "\n",
        "        # Recursively add children\n",
        "        for child in node.children:\n",
        "            child_id = add_node(child)\n",
        "            dot.edge(current_id, child_id)\n",
        "\n",
        "        return current_id\n",
        "\n",
        "    # Build the graph starting from the root\n",
        "    add_node(parse_tree)\n",
        "\n",
        "    # Render and display the graph\n",
        "    try:\n",
        "        if format == \"png\":\n",
        "            # Render to PNG and display\n",
        "            display(Image(dot.pipe(format='png')))\n",
        "        elif format == \"svg\":\n",
        "            # Render to SVG and display\n",
        "            from IPython.display import SVG\n",
        "            display(SVG(dot.pipe(format='svg')))\n",
        "        else:\n",
        "            print(f\"Unsupported format: {format}. Use 'png' or 'svg'.\")\n",
        "            return False\n",
        "        print(f\"Câu: {sentence}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating parse tree: {e}\")\n",
        "        return False\n",
        "\n"
      ],
      "metadata": {
        "id": "dM68sgOec132"
      },
      "id": "dM68sgOec132",
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === EXAMPLE USAGE ===\n",
        "if __name__ == \"__main__\":\n",
        "    # Test with a simple sentence\n",
        "    test_sentence = \"tôi ăn bánh mì\"\n",
        "    test_sentence = \"tôi mua bánh mì\"\n",
        "    test_sentence = \"tôi mua sinh tố\"\n",
        "    test_sentence = \"Anh thích cà phê cá koi\"\n",
        "    test_sentence = \"Học sinh học sinh học\"\n",
        "    test_sentence = \"Anh ấy làm tốt\"\n",
        "\n",
        "    parse_graph = visualize_parse_tree(test_sentence, format=\"png\")\n",
        "    parse_graph\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcsgb7g1uNG6",
        "outputId": "08f04737-62b6-42d7-e0d9-c1d25093eea6"
      },
      "id": "dcsgb7g1uNG6",
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to parse sentence: \"Anh ấy làm tốt\"\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}